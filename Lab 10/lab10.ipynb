{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './surnames/'\n",
    "Chinese = open(root+'Chinese.txt', encoding='utf-8').read().strip().split('\\n')\n",
    "Japanese = open(root+'Japanese.txt', encoding='utf-8').read().strip().split('\\n')\n",
    "Korean = open(root+'Korean.txt', encoding='utf-8').read().strip().split('\\n')\n",
    "English = open(root+'English.txt', encoding='utf-8').read().strip().split('\\n')\n",
    "Irish = open(root+'Irish.txt', encoding='utf-8').read().strip().split('\\n')\n",
    "Russian = open(root+'Russian.txt', encoding='utf-8').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]])\n",
      "torch.Size([2, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "#1 - a\n",
    "import string\n",
    "## We'll consider all ascii letters plus basic punctuation\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "all_letters = {character : index for index, character in enumerate(all_letters)}\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "## Function to iterate through a line of text encode each letter as a 1 x 57 vector in an nchar x 1 x 57 tensor\n",
    "def nameToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        if letter in all_letters:\n",
    "            tensor[li][0][all_letters[letter]] = 1\n",
    "    return tensor\n",
    "\n",
    "## Demonstration of the test name \"Aa\", notice the \"A\" is encoded as the 27th position, and \"a\" is the 1st position\n",
    "example = nameToTensor('Aa')\n",
    "print(example)\n",
    "\n",
    "## Also notice dim1 of the tensor is the number of charactersr in the name\n",
    "print(example.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 - a\n",
    "the first dimension represents the lengh of an input in terms of the character\n",
    "if we give different input, then depending on the input, the first dimension might change. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 - b\n",
    "the third dimension represents the indices of the characters in the input. \n",
    "if we give different input, the third dimension will not change. \n",
    "\n",
    "#2 - a\n",
    "\n",
    "6 comes from the number of languages (number of classes) for our data. \n",
    "we can technically change it, but it will harm our accuracy. \n",
    "\n",
    "#2 - b\n",
    "\n",
    "100 comes from the dimension of $a^{<0>}$. This should a parameter we can change in the architecture. \n",
    "\n",
    "#3 - a\n",
    "the input of the loop is the character array of all_letters\n",
    "\n",
    "#3 - b\n",
    "the output would be the probability that the ietters upto the loop's  iteration belonging to the languages. \n",
    "\n",
    "#3 - c\n",
    "We reinitialize hidden state because every time we are training a new model, we want a zeroed hidden states. Not the hidden state from the previous model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8460, -1.7866, -1.7009, -1.8808, -1.7380, -1.8094]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "class my_rnn(nn.Module):\n",
    "    \n",
    "    ## Constructor commands\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(my_rnn, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    ## Function to generate predictions\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "## Initialize model with random weights\n",
    "rnn = my_rnn(n_letters, 100, 6)\n",
    "\n",
    "## Format an example input name (Albert)\n",
    "test_input = nameToTensor('Albert')\n",
    "\n",
    "## Provide an initial hidden state (all zeros this time)\n",
    "hidden = torch.zeros(1, 100)\n",
    "\n",
    "## Generate output from the RNN\n",
    "output, next_hidden = rnn(test_input[0], hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of categories\n",
    "category_labels = ['Chinese', 'Japanese', 'Korean', 'English', 'Irish', 'Russian']\n",
    "\n",
    "## Dictionary of categories and names\n",
    "category_lines = {'Chinese': Chinese,\n",
    "                 'Japanese': Japanese,\n",
    "                 'Korean': Korean,\n",
    "                 'English': English,\n",
    "                 'Irish': Irish,\n",
    "                 'Russian': Russian}\n",
    "\n",
    "# Function to randomly sample a single example\n",
    "import random\n",
    "def randomTrainingExample():\n",
    "    ## Randomly choose a category index (ie: Chinese, etc.)\n",
    "    category = category_labels[random.randint(0, len(category_labels)-1)]\n",
    "    \n",
    "    ## Randomly choose a name in that category\n",
    "    name = category_lines[category][random.randint(0, len(category_lines[category])-1)]\n",
    "    \n",
    "    ## Convert the chosen example to a tensor\n",
    "    category_tensor = torch.tensor([category_labels.index(category)], dtype=torch.long)\n",
    "    line_tensor = nameToTensor(name)\n",
    "    \n",
    "    return category, name, category_tensor, line_tensor\n",
    "\n",
    "\n",
    "## Set learning rate\n",
    "learning_rate = 0.005\n",
    "\n",
    "## Define cost func\n",
    "cost_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "## Training function for a single input (name category, name)\n",
    "def train(category_tensor, line_tensor):\n",
    "    \n",
    "    ## initialize the hidden state\n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    ## set the gradient to zero\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    ## loop through the letters in the input, getting a prediction and new hidden state each time\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    ## Calculate cost and gradients\n",
    "    cost = cost_fn(output, category_tensor)\n",
    "    cost.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha = -learning_rate) ## This adds the LR times the gradient to each parameter \n",
    "\n",
    "    ## Return the output and cost\n",
    "    return output, cost.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializations\n",
    "n_iters = 10000\n",
    "cost_every_n = 25\n",
    "current_cost = 0\n",
    "track_cost = []\n",
    "\n",
    "### Iteratively update model from randomly chosen example\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, cost = train(category_tensor, line_tensor)\n",
    "    current_cost += cost\n",
    "    \n",
    "    # Save cost every 25 iterations\n",
    "    if iter % cost_every_n == 0:\n",
    "        track_cost.append(current_cost/cost_every_n)\n",
    "        current_cost = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> han\n",
      "(-0.11) Chinese\n",
      "(-2.47) Korean\n",
      "(-4.25) Irish\n",
      "(-5.39) English\n",
      "\n",
      "> Chris\n",
      "(-1.01) English\n",
      "(-1.24) Korean\n",
      "(-1.73) Russian\n",
      "(-2.42) Chinese\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "\n",
    "def predict(input_line, n_predictions=4):\n",
    "    print('\\n> %s' % input_line)\n",
    "    \n",
    "    ## Don't update gradient with any of these examples\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        ## Initialize new hidden state\n",
    "        hidden = rnn.initHidden()\n",
    "        \n",
    "        ## Convert input str to tensor\n",
    "        input_t = nameToTensor(input_line)\n",
    " \n",
    "        ## Pass each character into `rnn`\n",
    "        for i in range(input_t.size()[0]):\n",
    "            output, hidden = rnn(input_t[i], hidden)\n",
    "\n",
    "        # Get top N categories from output\n",
    "        topv, topi = output.topk(n_predictions, 1, True)\n",
    "        predictions = []\n",
    "\n",
    "        ## Go through the category predictions and save info for printing\n",
    "        for i in range(n_predictions):\n",
    "            value = topv[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, category_labels[category_index]))\n",
    "            predictions.append([value, category_labels[category_index]])\n",
    "\n",
    "## Try it out on a few examples:\n",
    "predict('han')\n",
    "predict('Chris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
