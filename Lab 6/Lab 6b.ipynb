{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import math\n",
    "\n",
    "# Unfortunately, knn functions prompt \"future warnings\", so the commands below turn these off\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that textfile containing these data uses a tab delimiter to separate the label and message\n",
    "sms = pd.read_csv(\"sms_spam.txt\", sep='\\t', names=['Label','Message'])\n",
    "\n",
    "## Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(sms, test_size=0.2, random_state=8)\n",
    "\n",
    "## Split outcome from predictors\n",
    "train_y = (train['Label'] == 'spam').astype(int)\n",
    "train_msg = train['Message']\n",
    "\n",
    "## Feature engineering functions\n",
    "def get_num(text):\n",
    "    return sum(map(str.isdigit, text))/len(text)\n",
    "def cap_percent(text):\n",
    "    return sum(map(str.isupper, text))/len(text)\n",
    "def alpha_percent(text):\n",
    "    return sum(map(str.isalnum, text))/len(text)\n",
    "\n",
    "## Define \"first_word\" function\n",
    "def first_word(text):\n",
    "    return text.split(sep=' ')[0].lower().replace('!','')\n",
    "\n",
    "## Create data frame with these features\n",
    "d = {'prop_num': train_msg.apply(get_num),\n",
    "     'prop_cap': train_msg.apply(cap_percent),\n",
    "     'prop_alp': train_msg.apply(alpha_percent),\n",
    "    'first': train_msg.apply(first_word)}\n",
    "train_X = pd.DataFrame(d)\n",
    "\n",
    "## Assemble final training X data\n",
    "train_X_ohe = pd.get_dummies(train_X, columns=['first'])\n",
    "train_X = train_X_ohe[['prop_num','prop_cap', 'prop_alp', 'first_urgent','first_free']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## Defining the models\n",
    "model1 = LogisticRegression(penalty='none')\n",
    "model2 = DecisionTreeClassifier(max_depth=5)\n",
    "model3 = Pipeline([('scaler', StandardScaler()),\n",
    "                  ('model', KNeighborsClassifier())])\n",
    "                  \n",
    "## Creating the ensemble\n",
    "my_ensemble = VotingClassifier(estimators=[('logr', model1),\n",
    "                                           ('tree', model2), \n",
    "                                           ('knn', model3)],\n",
    "                               voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9128026222243044\n",
      "[0.8453849485158784, 0.906203023823853, 0.9084395064728428]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(np.average(cross_val_score(my_ensemble, train_X, train_y, scoring='f1', cv=5)))\n",
    "\n",
    "## Individual models\n",
    "print([np.average(cross_val_score(model1, train_X, train_y, scoring='f1', cv=5)),\n",
    "       np.average(cross_val_score(model2, train_X, train_y, scoring='f1', cv=5)),\n",
    "       np.average(cross_val_score(model3, train_X, train_y, scoring='f1', cv=5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('logr', LogisticRegression(penalty='none')),\n",
      "                             ('tree', DecisionTreeClassifier(max_depth=5)),\n",
      "                             ('knn',\n",
      "                              Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                                              ('model',\n",
      "                                               KNeighborsClassifier(n_neighbors=3,\n",
      "                                                                    weights='distance'))]))],\n",
      "                 voting='soft')\n",
      "0.9167655692653746\n"
     ]
    }
   ],
   "source": [
    "#1-a\n",
    "\n",
    "\n",
    "params = {'logr__penalty': ['none','l2'], \n",
    "          'tree__max_depth': [4,5,6,7],\n",
    "         'knn__model__n_neighbors': [3,6,10,15],\n",
    "         'knn__model__weights': ['distance','uniform'],\n",
    "         'voting': ['soft','hard']}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(my_ensemble, param_grid=params, cv=5, scoring = 'f1').fit(train_X, train_y)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9328859060402686"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1-b\n",
    "test_y = (test['Label'] == 'spam').astype(int)\n",
    "test_msg = test['Message']\n",
    "\n",
    "## Create data frame with these features\n",
    "d = {'prop_num': test_msg.apply(get_num),\n",
    "     'prop_cap': test_msg.apply(cap_percent),\n",
    "     'prop_alp': test_msg.apply(alpha_percent),\n",
    "    'first': test_msg.apply(first_word)}\n",
    "\n",
    "test_X = pd.DataFrame(d)\n",
    "\n",
    "## Assemble final training X data\n",
    "test_X_ohe = pd.get_dummies(test_X, columns=['first'])\n",
    "test_X = test_X_ohe[['prop_num','prop_cap', 'prop_alp', 'first_urgent','first_free']]\n",
    "\n",
    "y_pred = grid.best_estimator_.predict(test_X)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_y, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
